"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent / 'src'))

import torch
import torch.optim as optim
from utils.config import Config
from models import create_model
from dataset import RTSDDataset, create_dataloaders, get_transforms_from_config
from training import Trainer, get_criterion
from utils.visualization import plot_training_history
from utils.logger import setup_logger
import random
import numpy as np


def set_seed(seed: int):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def main():
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    Config.print_config()
    Config.create_dirs()
    set_seed(Config.SEED)
    
    # –õ–æ–≥–≥–µ—Ä
    logger = setup_logger(Config.LOGS_DIR, 'training')
    logger.info("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è")
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    train_transform = get_transforms_from_config(Config, mode='train')
    val_transform = get_transforms_from_config(Config, mode='val')
    
    # –î–∞—Ç–∞—Å–µ—Ç—ã
    print("\nüìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
    train_dataset = RTSDDataset(
        anno_path=str(Config.TRAIN_ANNO),
        data_dir=str(Config.RTSD_DIR),
        label_map_path=str(Config.LABEL_MAP),
        transform=train_transform,
        crop_signs=Config.CROP_SIGNS
    )
    
    val_dataset = RTSDDataset(
        anno_path=str(Config.VAL_ANNO),
        data_dir=str(Config.RTSD_DIR),
        label_map_path=str(Config.LABEL_MAP),
        transform=val_transform,
        crop_signs=Config.CROP_SIGNS
    )
    
    print(f"‚úì Train: {len(train_dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"‚úì Val: {len(val_dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    # DataLoaders
    train_loader, val_loader = create_dataloaders(
        train_dataset,
        val_dataset,
        batch_size=Config.BATCH_SIZE,
        num_workers=Config.NUM_WORKERS,
        pin_memory=Config.PIN_MEMORY
    )
    
    # –ú–æ–¥–µ–ª—å
    print("\nüß† –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model = create_model(
        num_classes=Config.NUM_CLASSES,
        model_name=Config.MODEL_NAME,
        pretrained=Config.PRETRAINED,
        dropout=Config.DROPOUT
    )
    model.summary()
    
    # Loss, optimizer, scheduler
    criterion = get_criterion('CrossEntropy')
    optimizer = optim.Adam(
        model.parameters(),
        lr=Config.LEARNING_RATE,
        weight_decay=Config.WEIGHT_DECAY
    )
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=Config.SCHEDULER_FACTOR,
        patience=Config.SCHEDULER_PATIENCE
    )
    
    # Trainer
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        device=Config.DEVICE,
        scheduler=scheduler,
        checkpoint_dir=Config.CHECKPOINT_DIR,
        early_stopping_patience=Config.EARLY_STOPPING_PATIENCE
    )
    
    # –û–±—É—á–µ–Ω–∏–µ
    trainer.train(num_epochs=Config.NUM_EPOCHS)
    
    # –ì—Ä–∞—Ñ–∏–∫–∏
    plot_training_history(
        trainer.history['train_loss'],
        trainer.history['val_loss'],
        trainer.history['train_acc'],
        trainer.history['val_acc'],
        save_path=Config.RESULTS_DIR / 'training_history.png'
    )
    
    logger.info(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –õ—É—á—à–∞—è Acc: {trainer.best_val_acc:.2f}%")
    print("\n‚úì –ì–æ—Ç–æ–≤–æ!")


if __name__ == "__main__":
    main()